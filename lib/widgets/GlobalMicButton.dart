import 'dart:async';
import 'dart:collection';
import 'dart:math';
import 'package:flutter/material.dart';
import 'package:provider/provider.dart';
import '../Pages/User_Map.dart';
import 'package:speech_to_text/speech_to_text.dart' as stt;
import 'package:flutter_tts/flutter_tts.dart';
import '../Pages/User_SettingsProvider.dart';
import '../Pages/CAM_Analyze.dart';
import '../Pages/User_Home.dart';
import '../Pages/User_Setting.dart';
import '../Pages/User_NOKConnect.dart';
import '../Pages/User_NOKList.dart';
import 'package:lottie/lottie.dart';
import '../Pages/CAM_QR.dart';

class GlobalMicButton extends StatefulWidget {
  final VoidCallback onPressed;

  const GlobalMicButton({super.key, required this.onPressed});

  @override
  State<GlobalMicButton> createState() => _GlobalMicButtonState();
}

class _GlobalMicButtonState extends State<GlobalMicButton> {
  late stt.SpeechToText _speech;
  late FlutterTts _flutterTts;
  bool _isListening = false;
  bool _isProcessing = false;
  bool _showVoice = false;
  bool _showVoiceOut = false;
  final Queue<String> _commandQueue = Queue();
  bool _shouldContinueListening = true;
  String _lastCommand = '';

  @override
  void initState() {
    super.initState();
    _speech = stt.SpeechToText();
    _flutterTts = FlutterTts();

    _flutterTts.setLanguage("ko-KR");
    _flutterTts.setSpeechRate(0.8);
    _flutterTts.awaitSpeakCompletion(true);
  }

  Future<void> _speak(String text) async {
    print("ğŸ—£ï¸ ë§í•˜ê¸°: $text");
    await _speech.stop();
    await _flutterTts.speak(text);
  }

  Future<void> _startListening() async {
    if (!_shouldContinueListening) return;

    bool available = await _speech.initialize(
      onStatus: (status) {
        if (status == 'done' || status == 'notListening') {
          if (mounted) setState(() => _isListening = false);
        }
      },
      onError: (error) => print('âŒ ìŒì„±ì¸ì‹ ì˜¤ë¥˜: $error'),
    );

    if (available) {
      if (mounted) setState(() => _isListening = true);

      _speech.listen(
        localeId: 'ko_KR',
        partialResults: false,
        onResult: (result) {
          final command = result.recognizedWords.trim().toLowerCase();
          print("ğŸ§ ìµœì¢… ëª…ë ¹ì–´: $command");

          if (command.isNotEmpty && command != _lastCommand) {
            _lastCommand = command;
            _commandQueue.add(command);
            _processNextCommand();
          }
        },
      );
    } else {
      _speak("ìŒì„± ì¸ì‹ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤");
    }
  }

  Future<void> _processNextCommand() async {
    if (_isProcessing || _commandQueue.isEmpty) return;

    _isProcessing = true;
    final command = _commandQueue.removeFirst();

    await _speech.stop();
    _isListening = false;
    _shouldContinueListening = false;

    print("âš™ï¸ ì²˜ë¦¬ ì¤‘: $command");

    Future<void> navigate(Widget page, String message) async {
      if (!mounted) return;
      await _speak(message);
      Navigator.pushReplacement(
        context,
        MaterialPageRoute(builder: (_) => page),
      );
    }

    if (command.contains('ì„¤ì •')) {
      await navigate(UserSettingScreen(), "ì„¤ì • í˜ì´ì§€ë¡œ ì´ë™í• ê²Œìš”");
    } else if (command.contains('ì•ˆë‚´')) {
      await navigate(UserMapPage(), "ì†Œë¦¬ëˆˆ ë„¤ë¹„ê²Œì´ì…˜ìœ¼ë¡œ ì´ë™í• ê²Œìš”");
    } else if (command.contains('ì¸ì‹')) {
      await navigate(CameraAnalyzeScreen(), "ì†Œë¦¬ëˆˆ ë¬¸ì„œ ì¸ì‹ìœ¼ë¡œ ì´ë™í• ê²Œìš”");
    } else if (command.contains('í™ˆ') || command.contains('ë©”ì¸')) {
      await navigate(UserHomeScreen(), "ë©”ì¸ í™ˆìœ¼ë¡œ ì´ë™í• ê²Œìš”");
    } else if (command.contains('ë“±ë¡')) {
      await navigate(NOKConnectScreen(), "ë³´í˜¸ì ë“±ë¡ í˜ì´ì§€ë¡œ ì´ë™í• ê²Œìš”");
    } else if (command.contains('ëª©ë¡')) {
      await navigate(ProtectorListScreen(), "ë³´í˜¸ì ëª©ë¡ í˜ì´ì§€ë¡œ ì´ë™í• ê²Œìš”");
    } else if (command.contains('ì¹´ë©”ë¼') || (command.contains('QR'))) {
      await navigate(CAMQRScreen(), "ë³´í˜¸ì QR ë“±ë¡ í˜ì´ì§€ë¡œ ì´ë™í• ê²Œìš”");
    }else if (command.contains('ë’¤ë¡œ') || command.contains('ì´ì „')) {
      await _speak("ì´ì „ í˜ì´ì§€ë¡œ ì´ë™í• ê²Œìš”");
      if (mounted) Navigator.pop(context);
    } else if (command.contains("ì†Œë¦¬ ëˆˆ") || command.contains("ì†Œë¦¬ëˆˆ") || command.contains("ìš°ë¦¬ëŠ”") || command.contains("ìš°ë¦¬ëˆˆ") || command.contains("ìš°ë¦¬ ëˆˆ")){
      await _speak("ì†Œë¦¬ëˆˆ ì–´í”Œë¦¬ì¼€ì´ì…˜ì—ì„œëŠ” ì„¤ì •, ì•ˆë‚´, ì¸ì‹, í™ˆ, ë“±ë¡, ëª©ë¡ ê°™ì€ ìŒì„± ëª…ë ¹ì–´ë¡œ ê°ê°ì˜ í˜ì´ì§€ë¡œ ì´ë™í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
          "ì´ì „ ì´ë¼ê³  ë§í•˜ë©´ ì´ì „ í˜ì´ì§€ë¡œ ëŒì•„ê°ˆ ìˆ˜ ìˆê³ , ê³ ë§ˆì›Œ, ëì–´, ì¢…ë£Œë¼ê³  ë§í•˜ë©´ ìŒì„± ì•ˆë‚´ê°€ ì¢…ë£Œë©ë‹ˆë‹¤."
          "ì§€ê¸ˆ ì–´ë–¤ í˜ì´ì§€ì— ìˆëŠ”ì§€ í—·ê°ˆë¦¬ì‹ ë‹¤ë©´ ì–¸ì œë“ ì§€ ì†Œë¦¬ëˆˆì´ë¼ê³  ë¶ˆëŸ¬ì£¼ì„¸ìš”."
          "í˜„ì¬ í˜ì´ì§€ê°€ ë¬´ì—‡ì¸ì§€ì™€ í•¨ê»˜, ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ìŒì„± ëª…ë ¹ì–´ë¥¼ ì¹œì ˆí•˜ê²Œ ì•ˆë‚´í•´ë“œë¦½ë‹ˆë‹¤.");
    } else if (command.contains('ìŒì„± ëª…ë ¹ì–´') || command.contains('ëª…ë ¹ì–´')) {
      await _speak("ì§€ê¸ˆ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ëª…ë ¹ì–´ëŠ” ì„¤ì •. ì•ˆë‚´. ì¸ì‹. í™ˆ. ë“±ë¡. ëª©ë¡. ì†Œë¦¬ëˆˆ. ì´ì „, ëª…ë ¹ì–´. ìŒì„± ëª…ë ¹ì–´ê°€ ìˆìŠµë‹ˆë‹¤");
    } else if (command.contains('ê³ ë§ˆì›Œ') ||
        command.contains('ëì–´') ||
        command.contains('ì¢…ë£Œ')) {
      await _speak("ì–¸ì œë“  ë‹¤ì‹œ ë¶ˆëŸ¬ì£¼ì„¸ìš”");
    } else if (command.contains('ì „ì†¡')) {
      // final isInAnalyzeScreen =
      //     context.widget.runtimeType == CameraAnalyzeScreen;
      //
      // if (isInAnalyzeScreen) {
      //   final state = context.findAncestorStateOfType<CameraAnalyzeState>();
      //   if (state != null) {
      //     state.captureAndSendScreen();
      //   } else {
      //     final unknowns = [
      //       "ì£„ì†¡í•´ìš”. ë‹¤ì‹œ ë§ì”€í•´ ì£¼ì‹œê² ì–´ìš”?",
      //       "ì˜ ëª» ë“¤ì—ˆì–´ìš”. í•œ ë²ˆ ë” ë§ì”€í•´ ì£¼ì„¸ìš”.",
      //       "ë§ì”€ì„ ë†“ì³¤ì–´ìš”. ë‹¤ì‹œ í•œ ë²ˆ ë¶€íƒë“œë¦´ê²Œìš”.",
      //     ];
      //     await _speak(unknowns[Random().nextInt(unknowns.length)]);
      //     _shouldContinueListening = true;
      //   }
      // }
    }

    _isProcessing = false;

    if (_commandQueue.isNotEmpty) {
      _processNextCommand();
    } else if (_shouldContinueListening &&
        mounted &&
        ModalRoute.of(context)?.isCurrent == true) {
      await Future.delayed(const Duration(milliseconds: 300));
      _startListening();
    }
  }

  @override
  Widget build(BuildContext context) {
    return Padding(
      padding: const EdgeInsets.only(bottom: 50),
      child: Stack(
        clipBehavior: Clip.none,
        children: [
          if (_showVoice)
            Positioned(
              bottom: -70,
              left: -22,
              child: AnimatedOpacity(
                opacity: 1.0,
                duration: const Duration(milliseconds: 1000),
                child: AnimatedScale(
                  scale: 1.0,
                  duration: const Duration(milliseconds: 1000),
                  child: Lottie.asset('assets/lottie/Voice.json', width: 200),
                ),
              ),
            ),
          if (_showVoiceOut)
            Positioned(
              bottom: -70,
              left: -22,
              child: AnimatedOpacity(
                opacity: 1.0,
                duration: const Duration(milliseconds: 500),
                child: Lottie.asset('assets/lottie/VoiceOut.json', width: 200),
              ),
            ),
          Positioned(
            bottom: -26,
            left: 24,
            child: GestureDetector(
              onTap: () async {
                widget.onPressed();
                Provider.of<UserSettingsProvider>(
                  context,
                  listen: false,
                ).vibrate();
                _shouldContinueListening = true;
                _lastCommand = '';

                setState(() {
                  _showVoice = true;
                  _showVoiceOut = false;
                });

                await _speak("ë¶€ë¥´ì…¨ë‚˜ìš”?");
                await Future.delayed(const Duration(milliseconds: 100));
                await _startListening();

                await Future.delayed(const Duration(milliseconds: 5000));
                if (mounted) {
                  setState(() {
                    _showVoice = false;
                    _showVoiceOut = true;
                  });
                }
              },
              child: SizedBox(
                width: 110,
                height: 110,
                child: Image.asset(
                  'assets/images/micBtn.png',
                  fit: BoxFit.contain,
                ),
              ),
            ),
          ),
        ],
      ),
    );
  }

  @override
  void dispose() {
    print("ğŸ§¹ dispose() í˜¸ì¶œë¨: ë¦¬ìŠ¤ë‹ ì¤‘ë‹¨ ë° ì´ˆê¸°í™”");
    _speech.stop();
    _flutterTts.stop();
    _commandQueue.clear();
    _shouldContinueListening = false;
    _isListening = false;
    _isProcessing = false;
    super.dispose();
  }
}